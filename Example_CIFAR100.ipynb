{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_CIFAR100.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMXXTU5Nk4AtadgO2eLJC9/"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYtYUpvbxZRt"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. \n",
        "#There are 500 training images and 100 testing images per class. \n",
        "#The 100 classes in the CIFAR-100 are grouped into 20 superclasses.\n",
        "from tensorflow.keras.datasets import cifar100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKiZGvWyxt54"
      },
      "source": [
        "batch_size=100\n",
        "num_classes=100\n",
        "epochs=30\n",
        "\n",
        "\n",
        "(xt,yt),(xtest,ytest)= cifar100.load_data()\n",
        "\n",
        "_,rows, cols, channels = xt.shape\n",
        "\n",
        "xt=xt.astype('float32')\n",
        "xtest=xtest.astype('float32')\n",
        "\n",
        "xt=xt/255\n",
        "xtest=xtest/255\n",
        "\n",
        "yt=tf.keras.utils.to_categorical(yt,num_classes)\n",
        "ytest=tf.keras.utils.to_categorical(ytest,num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W50MbGmixwDt"
      },
      "source": [
        "basic=False\n",
        "if(basic):\n",
        "  #Basic CNN that produces overfitting\n",
        "  inputs=tf.keras.layers.Input(shape=(rows,cols,channels))\n",
        "  x=tf.keras.layers.Conv2D(64,kernel_size=(3,3),activation='relu')(inputs)\n",
        "  x=tf.keras.layers.Conv2D(128,kernel_size=(3,3),activation='relu')(x)\n",
        "  x=tf.keras.layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "  x=tf.keras.layers.Flatten()(x)\n",
        "  x=tf.keras.layers.Dense(100,activation='relu')(x)\n",
        "  x=tf.keras.layers.Dense(num_classes,activation='softmax')(x)\n",
        "  \n",
        "if(not basic):\n",
        "  #Not so basic CNN that produces overfitting as well.\n",
        "  #Probably because the dataset.\n",
        "  inputs=tf.keras.layers.Input(shape=(rows,cols,channels))\n",
        "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
        "  x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "  x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "  x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        " \n",
        "  x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "  x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "  x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "  \n",
        "  x=tf.keras.layers.Flatten()(x)\n",
        "  x=tf.keras.layers.Dense(100,activation='relu')(x)\n",
        "  x=tf.keras.layers.Dense(num_classes,activation='softmax')(x)\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDdlmmbKxyg6"
      },
      "source": [
        "stochastic_gradient_descent = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,beta_2=0.9)#SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=tf.keras.losses.categorical_crossentropy,optimizer=stochastic_gradient_descent,metrics=['categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ln7RRI6x0DZ"
      },
      "source": [
        "model.fit(xt,yt,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(xtest,ytest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnLl1z3b0sMo"
      },
      "source": [
        "points = model.evaluate(xtest, ytest, verbose=1)\n",
        "print(points)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}